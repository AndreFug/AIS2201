{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62d7774-8539-4d71-a6d4-2d650e8c6230",
   "metadata": {},
   "source": [
    "<nav class=\"navbar navbar-default\">\n",
    "  <div class=\"container-fluid\">\n",
    "    <div class=\"navbar-header\" style=\"float: left\">\n",
    "        <a class=\"navbar-brand\" href=\"0_Index.ipynb\" target=\"_self\"> <h2> &uarr; Back to front page</h2></a>\n",
    "    </div>\n",
    "  </div>\n",
    "</nav>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86114d6b",
   "metadata": {},
   "source": [
    "# Processing audio signals\n",
    "\n",
    "Now that we have familiarized ourselves with the main components of an audio signal, it is time to explore some simple audio manipulation. Once again, we start by loading the contents of the audio file `sample_music.wav` using scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ded33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile # Import module for handling of .wav audio files\n",
    "from IPython.display import Audio   # For loading embedded audio player\n",
    "import numpy as np\n",
    "\n",
    "fs, sampleData = wavfile.read(\"sample_audio.wav\") # \"fs\" is sampling frequency, \"sampleData\" is the sequence of measurements\n",
    "print(\"Data type in raw sample data: \", type(sampleData[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0682a",
   "metadata": {},
   "source": [
    "Processing audio typically involves subjecting the signal samples to som mathematical operation. However, it is important to note that each value in the `sampleData` array is of type `int16`, which is the standard sample resolution for audio recordings. When attempting to manipulate audio samples this may result in some severe pitfalls which can be demonstrated when attempting to scale up the values in `sampleData`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7c1b4",
   "metadata": {},
   "source": [
    "## a)\n",
    "\n",
    "Create a figure which shows a plot of both `sampleData` and `2*sampleData`, [here](Figures/audio_processing.png) is a example of what this plot should look like. Give a thorough explanation of why the plot for `sampleData*2` is so evidently clipped compared to `sampleData`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a576b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2208dba4cd37c952cbb4dfb4c5be43d3",
     "grade": true,
     "grade_id": "cell-1be8cfc53e0b43b6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15285e27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f79b3aae7bf9d2d2e0793757941af98",
     "grade": true,
     "grade_id": "cell-23a6b1aea999cf2c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "ANSWER THEORY QUESTIONS HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c06c09",
   "metadata": {},
   "source": [
    "In order to avoid the issues explored in problem **a)** when processing these samples, it is usually preferable to convert the samples to floating point values (`float`). For instance, the line \n",
    "```python\n",
    "xn = sampleData/max(abs(sampleData))\n",
    "```\n",
    "accomplishes this by using normal division to create a new array `xn` where the sample values are floating point values. In addition the range of values in the signal is scaled down to $-1.0 \\leq x[n] \\leq 1.0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = sampleData/max(abs(sampleData))\n",
    "print(\"Data type in scaled array 'xn': \", type(xn[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a846b",
   "metadata": {},
   "source": [
    "We are now ready to begin adding sound effects to our music sample. One of the most useful tools available to us when modifying entire arrays is [slicing](https://www.w3schools.com/python/numpy/numpy_array_slicing.asp), as it allows us to acces ond/or overwrite a subset of the elements in our array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12f569",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "Use list slicing to reduce the amplitude of the first $10$ seconds of the audio recording. The resulting audio output $y(t)$ may be described in relation to the original audio signal $x(t)$ using the follwoing equation. \n",
    "\n",
    "$$y(t) = \n",
    "\\begin{cases}\n",
    "\\frac{1}{8}\\cdot x(t), & t\\leq 10s \\\\\n",
    "x(t), & t > 10s\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d6605",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0cc46baf52af7678ffdf00b7215054d",
     "grade": true,
     "grade_id": "cell-7b9def5694d7bb27",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e02fd",
   "metadata": {},
   "source": [
    "You can use the code below to listen to the new modified audio signal in the array `yn`. Describe what you hear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540528d0-3707-4a6f-b288-c562f3b04cfe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65aee64be8dfdd96b271ee57198154b2",
     "grade": true,
     "grade_id": "cell-7d97355fc0304121",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "ANSWER THEORY QUESTIONS HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aacdc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following lines to listen to the audio signal `yn`\n",
    "Audio(np.int16(yn*0x7FFF), rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd764b",
   "metadata": {},
   "source": [
    "The audio signal in `sample_audio.wav` is what known as a *mono* signal, meaning it has only one channel. When played on a speaker system with two speakers (which is quite common), the exact same audio output will play from each of the speakers. *Stereo* audio signals are generally much more common, as having one dedicated audio stream for left and right speaker allows for more spatial depth in the listening experience. In Python, stereo signals can be represented using a $2\\times N$ 2-dimensional array. Given an audio signal consisting of the left speaker audio stream $x_{left}[n]$ and the right speaker audio stream $x_{right}[n]$, the resulting 2D array should adhere to the following pattern:\n",
    "\n",
    "<img src=\"Figures/stereo_audio.png\" style=\"width: 800px; margin-left: 100px\" />\n",
    "\n",
    "What we wish to do is modify our `sample_aduio.wav` signal in such a way that the first $10$ seconds of our audio stream sound like they originates on the left side of the listener, and the rest of the audio stream sounds like it originates to the right of the listener. This can be done by alternately reducing the amplitude of each audio channel.\n",
    "\n",
    "Let's call our stereo audio signal $v_m(t)$, where $m$ is channel and $t$ i is time in seconds. Given a source single-channel audio $x(t)$ can then describe the stereo signal as follows:\n",
    "\n",
    "$$v_m(t) = \n",
    "\\begin{cases}\n",
    "x(t), & t\\leq 10s \\text{ and } m=0\\\\\n",
    "\\frac{1}{8}\\cdot x(t), & t > 10s \\text{ and } m=0\\\\\n",
    "\\frac{1}{8}\\cdot x(t), & t\\leq 10s \\text{ and } m=1\\\\\n",
    "x(t), & t > 10s \\text{ and } m=1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## c)\n",
    "Create a stereo signal `v` which adheres to the specifications described above.\n",
    "\n",
    "*P.S. Given two one-dimensional arrays `x1` and `x2` of equal length $N$, these can be combined into a $2\\times N$ matrix `X` using [`numpy.concatenate()`](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) as follows:*\n",
    "```Python\n",
    "X = np.concatenate(([x1], [x2]), axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4460ef9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7e93a697b419688a9cbfe06364fa3d2",
     "grade": true,
     "grade_id": "cell-18253b8d121354c6",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b322df-bca1-41e7-844e-24c7df52634c",
   "metadata": {},
   "source": [
    "Use the following code cell to listen to the audio signal `v`, and verify the spatial properties of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f32aa8-51c6-4900-aa33-8d708e4bc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following lines to listen to the audio signal `v`\n",
    "Audio(np.int16(v/max(abs(v))*0x7FFF), rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3f9d2-d639-4b97-ba77-632339159702",
   "metadata": {},
   "source": [
    "<br>\n",
    "<nav class=\"navbar navbar-default\">\n",
    "  <div class=\"container-fluid\">\n",
    "    <div class=\"navbar-header\" style=\"float: left\">\n",
    "      <a class=\"navbar-brand\" href=\"1_the_audio_file.ipynb\" target=\"_self\">&lt; Previous page: <i>Exploring the audio file</i></a>\n",
    "      </div>\n",
    "    <div class=\"navbar-header\" style=\"float: right\">\n",
    "      <a class=\"navbar-brand\" href=\"3_sinusoids.ipynb\" target=\"_self\">Next page: <i>Sinusoids and their frequency representation</i> &gt;</a>\n",
    "    </div>\n",
    "  </div>\n",
    "</nav>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
