{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f195fb-ba27-453a-bcbc-ddf97a4d6439",
   "metadata": {},
   "source": [
    "# Filtering a noisy speech signal\n",
    "\n",
    "**Topics**\n",
    "* Intro to wiener filters\n",
    "\n",
    "**Learning goals**\n",
    "* Familiarity with calculating filter properties based on signal analysis\n",
    "* Designing a filter with arbitrary frequency response using the frequency sampling method\n",
    "\n",
    "**Libraries and notebook config:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb452e59-141d-4723-8139-407e671cccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import scipy.signal as sig\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 4.5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"axes.xmargin\"] = 0.0\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9228c-adc2-495f-9c6e-80a8603df95a",
   "metadata": {},
   "source": [
    "## A brief intro to Wiener Filtering of speech signals\n",
    "\n",
    "By now you should be familiar with the frequency domain properties of FIR filters, and how designing a FIR filter can be fairly straightforward once you know the deisired shape of the frequency response. But what if there is no simple lowpass or highpass filter you can design beforehand which will do the trick? In this problem we will have a look at a method for designing a filter for suppressing noise in a speech signal which may be automated (although we will do it manually here).\n",
    "\n",
    "First, let's get some definitions out of the way. A speech signal $s[n]$ is recorded alongside noise $v[n]$ (in this example we simply use white noise, but a possible practical usecase may be wind causing disturbances in the microphone). The samples produced by the microphone are $x[n] = s[n] + v[n]$, and our goal is to calculate a filter $h[n]$ which when applied to $x[n]$ will maximize the Signal-to-Noise Ratio of the output, where the output Signal-to-Noise ratio can be described as:\n",
    "\n",
    "$$\\text{SNR} = \\frac{E(|h[n]*s[n]|^2)}{E(|h[n]*v[n]|^2)}$$\n",
    "\n",
    "This ideal filter is known as a [wiener filter](https://en.wikipedia.org/wiki/Wiener_filter) and may, assuming there is no correlation between $s[n]$ and $v[n]$ (i.e. $E(s[n]\\cdot v[n-l]) = 0$), be expressed as\n",
    "\n",
    "$$H_{\\text{opt}}(\\hat{\\omega}) = \\frac{S_{ss}(\\hat{\\omega})}{S_{xx}(\\hat{\\omega})}$$\n",
    "\n",
    "where $S_{ss}(\\hat{\\omega})$ is the power spectral density (PSD) of the speech signal $s[n]$, and $S_{xx}(\\hat{\\omega})$ is the PSD of the sampled signal $x[n]$. OK, so far so good, but this leaves us with a new problem: that of estimating what the PSD of a speech signal $s[n]$ which is buried in noise. Here is where we can employ one of signal processing's neat little tricks: *it is often far easier acquire information on interfering noise rather than a desired signal, and if you can design a filter to maximise Noise-to-Signal Ratio, it's complementary filter should maximize Signal-to-Noise Ratio.*\n",
    "\n",
    "In a speech signal for instance, we can assume that there will be intermittent pauses between words/sentences where $s[n] \\approx 0$ and $x[n] \\approx v[n]$. The code cell below loads the content of an audio file `speech_w_noise.wav` into an array `xn`, and both plots the audio envelope as well as loading an audio playback of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551dfe53-6edc-4c66-9c9a-a479c6c79304",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, data = wavfile.read(\"speech_w_noise.wav\")\n",
    "xn = data/max(abs(data))\n",
    "\n",
    "plt.close(1); plt.figure(1, figsize=(12,4))\n",
    "plt.plot(np.linspace(0, len(xn)/fs, len(xn), endpoint=False), xn)\n",
    "plt.grid(True)\n",
    "plt.xlim([0, len(xn)/fs])\n",
    "\n",
    "Audio(xn, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30a328-b606-4a2f-b14e-29c4e661e7b6",
   "metadata": {},
   "source": [
    "## a)\n",
    "\n",
    "Study the audio envelope in the above figure. Use slicing to select one signal segment containing only noise, and one signal segment dominated by speech (the longer the better). If in doubt, try listening to the segments to see if they have the desired content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53169122-7cd1-4f50-8d01-f4b2d5507616",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a35209ad5f015d991f62e8ae3d5b38de",
     "grade": true,
     "grade_id": "cell-953dcb68baf850d1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE IN THIS CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1589ddc-c6f8-4c63-bd0e-9580aeeed326",
   "metadata": {},
   "source": [
    "## b) \n",
    "Choose a number of filter taps which you think sounds promising (e.g. $M=128$), and use function [welch](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html) to estimate the power spectral density `S_xx` and `S_vv` of both segments from part **a)** with resolution $M$ (`nfft=M`). Then, calculate the frequency response $H_v(\\hat{\\omega})=\\frac{S_{vv}(\\hat{\\omega})}{S_{xx}(\\hat{\\omega})}$ and show the magnitude response curve in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effc03f-7375-4c36-9877-f4718b5237f4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d6a5260a60db809eda42d1370ace414",
     "grade": true,
     "grade_id": "cell-eceab675389bc6ee",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE IN THIS CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e964c78-7b51-4626-ac64-46acf88e7d6b",
   "metadata": {},
   "source": [
    "[Here](figures/task4b_lf.png) is an example of what the noise enhancing filter's magnitude response might look like. Here, i have set an upper limit for filter gain at $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa9c75-ab39-45b2-b62c-d9662f91550a",
   "metadata": {},
   "source": [
    "## c) \n",
    "Calculate the frequency response of the complimentary filter  $H_s(\\hat{\\omega}) = 1 - H_v(\\hat{\\omega})$. The array of $M$ values representing $H_s(\\hat{\\omega})$ can soon be transformed back to the time domain to acquire an impulse response $h[n]$, but there is a final adjustment we need to make first: \n",
    ">Seeing as our filter is supposed to be causal, it is practically impossible for the filter to have a phase response $\\angle H_s(\\hat{\\omega}) = 0$, but this is basically what our current frequency response attempts to do. To account for this, we must add $D=\\frac{M-1}{2}$ samples of delay to ensure symmetry properties of the impulse response $h_s[n]$. This is done by *in the frequency domain* adjusting the angle of the frequency response accordingly:\n",
    ">\n",
    ">$$H_s(\\hat{\\omega}) \\cdot e^{-j\\hat{\\omega}D}$$\n",
    ">\n",
    ">PS: Using this method it is perfectly possible to impose a fractional delay (e.g. $63.5$ samples)\n",
    "\n",
    "Once you have your phase adjusted frequency response, an impulse response with somewhat suitable frequency-domain properties may be found using `irfft`. What we are doing is often referred to as the frequency sampling filter design method, and is explained thoroughly in chapter 7.4. \n",
    "\n",
    "Verify your work by creating a figure showing both a high-resolution magnitude response $|H_s(\\hat{\\omega})|$ of the filter, as well as the impulse response $h[n]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55e37d-2362-458c-80b8-cb86427a55b9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abc3c6c2b04d45d5695bfabe740af000",
     "grade": true,
     "grade_id": "cell-e58fcc94cf31df8a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE IN THIS CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60736939-7442-4a4d-9cd9-599383bec2b1",
   "metadata": {},
   "source": [
    "[Here](figures/task4c_lf.png) is an example of what the speech enhancing filter's magnitude response might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7640d4c-adf9-4438-866f-36202dea28ae",
   "metadata": {},
   "source": [
    "## d) \n",
    "\n",
    "Use the filter you calculated in **c)** to filter the signal $x[n]$, and listen to the result. Do not expect crystal clear audio, this noise filtering technique has a lot of potential for improvement. However, there should absolutely be a noticeable reduction in noise level. \n",
    "\n",
    "Finally, plot the envelope of the filtered audio signal alongside the original, and comment on the difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c62a8-2e6e-4dc1-aba3-b3b539123a3f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a11d75ea0354ac2ab55905753dbb4c80",
     "grade": true,
     "grade_id": "cell-06ad0be243e94c4a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE IN THIS CELL:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
